{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stereovision\n",
    "\n",
    "![Suzanne](main.png)\n",
    "\n",
    "Stereovision is a discipline that deals with the reconstruction of 3D information from images. For the reconstruction of a point, several images of this point are needed. These images must be taken from different points of view. The key step of the reconstruction, which is often problematic, is to identify the images of the point to be reconstructed in each view.\n",
    "\n",
    "## Epipolar Geometry\n",
    "\n",
    "Epipolar geometry involves two cameras. The epipolar geometry describes the geometric properties between two views of the same scene and depends only on the intrinsic parameters of the cameras and their relative positions. It provides, in particular, the epipolar constraint, which will be very useful to produce the matches between views.\n",
    "\n",
    "## The Fondamental Matrix\n",
    "\n",
    "![Epipolar Geometry - Sanyam Kapoor](epipolar.png)\n",
    "\n",
    "Let us imagine that we have two images, right and left, of the world space. Let's take a point $\\vec{x}$ in the right image space. The point $\\vec{X}$ of the world space, of which $\\vec{x}$ is the image, can be anywhere on the line passing through $\\vec{x}$ and the optical center of the right camera. We will call this line the back-projected ray of $\\vec{x}$. Let us note $\\vec{x}'$ the image of $\\vec{X}$ in the left image space. The locus of $\\vec{x}'$ is therefore the image line of the back-projected ray of $\\vec{x}$. This line is called the epipolar line and is denoted $\\vec{l}'$. The epipolar line passes through the epipole $\\vec{e}'$, image of the optical center of the right camera.\n",
    "\n",
    "In 2D projective geometry, a line with equation $ax+by+c = 0$ is represented by a vector with three components $(a, b, c)^T$ defined to within one factor. Thus, we have the following relationship:\n",
    "\n",
    ">The point $\\vec{x}$ belongs to the line $\\vec{l}$ if and only if $x^T\\vec{l} = 0$.\n",
    "\n",
    "Moreover, in 2D projective geometry, the following remarkable relations are valid:\n",
    "\n",
    "- The intersection of two lines $l$ and $l'$ is given by $x = l \\times l'$,\n",
    "- The line passing through two points $x$ and $x'$ is given by $l = x \\times x'$.\n",
    "\n",
    "Note that the vector product can be written as a product of matrix $x \\times y = [x]_\\times y$ where\n",
    "\n",
    "$$[x]_\\times = \\begin{pmatrix} 0 & −x3 & x2 \\\\ x3 & 0 & −x1 \\\\ −x2 & x1 & 0 \\end{pmatrix}$$\n",
    "\n",
    "To find the equation of the epipolar line in the left image space, we just need to find the coordinates of two points of this line. The first is the image $P'\\vec{C}$ of the optical center $\\vec{C}$ of the right camera where $P'$ is the projection matrix of the left camera. The second is $P'P^{+}\\vec{x}$ where $P^{+}$ is the pseudo inverse of the projection matrix $P$ of the right camera. The epipolar line thus has the equation $l' = [P'\\vec{C}]_\\times{}P'P^{+}\\vec{x} = F\\vec{x}$ with $F = [P'\\vec{C}]_\\times{}P'P^{+}$. $F$ is called fundamental matrix.\n",
    "\n",
    "Since the epipolar line $\\vec{l}' = F\\vec{x}$ is the locus of $\\vec{x}'$, $\\vec{x}'$ therefore belongs to $\\vec{l}'$ which leads to the epipolar constraint :\n",
    "\n",
    ">**The fundamental matrix is such that for any pair of points corresponding $\\vec{x} \\leftrightarrow \\vec{x}'$ in the two images, we have $\\vec{x}'^{T}F\\vec{x} = 0$.**\n",
    "\n",
    "## Computation of the fundamental matrix\n",
    "\n",
    "The fundamental matrix $F$ has seven degrees of freedom. It has nine components but these are defined to within one scale factor, which removes one degree of freedom. Moreover, the matrix $F$ is a singular matrix ($det(F) = 0$) which gives us seven degrees of freedom. So we need at least seven correspondences to compute $F$. The equation $x'^{T}_iFx_i = 0$ and the seven correspondences allow us to write a system of equations of the form $Af = 0$, where $f$ is the vector which contains the components of the matrix $F$. Let us assume that $A$ is a 7×9 matrix of rank 7. The general solution of $Af = 0$ can be written $\\alpha f_1 + (1-\\alpha) f_2$ where $f_1$ and $f_2$ are two particular independent solutions of $Af = 0$. We then use the singularity constraint $det(\\alpha F_1 + (1 - \\alpha)F_2) = 0$ to determine $\\alpha$. Since the singularity constraint gives rise to a third degree equation, we may have one or three solutions for $F$.\n",
    "\n",
    "## OpenCV\n",
    "\n",
    "In practice you will use the OpenCV library. In python, you have access to its functions through the `cv2` module.\n",
    "\n",
    "You can find help with the calibration and reconstruction functions on the site https://docs.opencv.org/4.0.0/d9/d0c/group__calib3d.html\n",
    "\n",
    "## Goal\n",
    "\n",
    "In the zip of the statement you will find two sequences of images taken by two cameras during the scanning of an object by a laser plane.\n",
    "\n",
    "![Laser](scanRight/scan0010.png)\n",
    "\n",
    "You will also find shots of a checkerboard in different positions that will help you calibrate your cameras.\n",
    "\n",
    "![Damier](chessboards/c2Right.png)\n",
    "\n",
    "The goal is to reconstruct the scanned object in 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.47041321e-08 -1.22159145e-06  8.36303231e-04]\n",
      " [ 3.07075828e-06  6.07967918e-08 -1.40288079e-02]\n",
      " [-1.92262090e-03  1.23214259e-02  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Etape 1 \n",
    "#Recuper les données de nos deux caméras\n",
    "\n",
    "#Prepa\n",
    "chessboardSize = (7,7)\n",
    "frameSize = (1920,1080)\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0],0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpointsL = [] # 2d points in image plane.\n",
    "imgpointsR = [] # 2d points in image plane.\n",
    "\n",
    "imagesLeft = sorted(glob.glob('chessboards/c*L*.png'))\n",
    "imagesRight = sorted(glob.glob('chessboards/c*R*.png'))\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if retL and retR == True:\n",
    "\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        cornersL = cv.cornerSubPix(grayL, cornersL, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "        cornersR = cv.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv.calibrateCamera(objpoints, imgpointsL, frameSize, None, None)\n",
    "heightL, widthL, channelsL = imgL.shape\n",
    "newCameraMatrixL, roi_L = cv.getOptimalNewCameraMatrix(cameraMatrixL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv.calibrateCamera(objpoints, imgpointsR, frameSize, None, None)\n",
    "heightR, widthR, channelsR = imgR.shape\n",
    "newCameraMatrixR, roi_R = cv.getOptimalNewCameraMatrix(cameraMatrixR, distR, (widthR, heightR), 1, (widthR, heightR))\n",
    "\n",
    "#rotation matrix => convert vector to matrix\n",
    "rmatLeft = cv.Rodrigues(rvecsL[2])[0]\n",
    "rmatRight = cv.Rodrigues(rvecsR[2])[0]\n",
    "\n",
    "#full [R|t] matrix => add t in R\n",
    "rotMatRight = np.concatenate((rmatRight,tvecsR[0]), axis=1)\n",
    "rotMatLeft = np.concatenate((rmatLeft,tvecsL[0]), axis=1)\n",
    "\n",
    "#camera matrix (A [R|t])\n",
    "camLeft = cameraMatrixL @ rotMatLeft\n",
    "camRight = cameraMatrixR @ rotMatRight\n",
    "\n",
    "# find cx and cy for both cameras\n",
    "camWorldCenterLeft = np.linalg.inv(np.concatenate((rotMatLeft,[[0,0,0,1]]), axis=0)) @ np.transpose([[0,0,0,1]])\n",
    "camWorldCenterRight = np.linalg.inv(np.concatenate((rotMatRight,[[0,0,0,1]]), axis=0)) @ np.transpose([[0,0,0,1]])\n",
    "\n",
    "flags = 0\n",
    "flags = cv.CALIB_FIX_INTRINSIC\n",
    "# Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.\n",
    "# Hence intrinsic parameters are the same \n",
    "\n",
    "criteria_stereo= (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix\n",
    "retStereo, newCameraMatrixL, distL, newCameraMatrixR, distR, rotMatrix, transMatrix, essentialMatrix, fundamentalMatrix = cv.stereoCalibrate(objectPoints=objpoints, \n",
    "    imagePoints1=imgpointsL, imagePoints2=imgpointsR, cameraMatrix1 = newCameraMatrixL, distCoeffs1= distL, \n",
    "    cameraMatrix2=newCameraMatrixR, distCoeffs2=distR, imageSize= grayL.shape[::-1], R=rmatLeft, T= tvecsL[0], flags=flags, criteria=criteria_stereo)\n",
    "\n",
    "\n",
    "#full [R|t] matrix => add t in R\n",
    "newRotMatLeft = np.concatenate((rotMatrix, transMatrix), axis=1)\n",
    "newCamLeft = newCameraMatrixL @ newRotMatLeft\n",
    "newCamCenterLeft = np.linalg.inv(np.concatenate((newRotMatLeft,[[0,0,0,1]]), axis=0)) @ np.transpose([[0,0,0,1]])\n",
    "\n",
    "#Parametres intrinsèque, skew = 0\n",
    "    #Assume pixel is square -> focalLengthX == focalLengthY\n",
    "focalLengthX = newCameraMatrixL[0,0]\n",
    "focalLengthY = newCameraMatrixR[1,1]\n",
    "    #Assume prinicpal point is at the center of the image -> img not cropped\n",
    "principalPointX = newCameraMatrixL[0,2]\n",
    "principalPointY = newCameraMatrixR[1,2]\n",
    "\n",
    "print(fundamentalMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etape 2\n",
    "\n",
    "# 1. For each pixel in first image find corresponding epipolar line in second images\n",
    "# 2. Examine all corresponding pixels on epipolar line and pick best match\n",
    "# 3. Triangulate matches to get depth information\n",
    "\n",
    "#Stereo rectification : on met les deux caméra à même \"hauteur\" => leur epilines vont coincider == scanlines\n",
    "#Step 1 : Find projective transformation HLeft and HRight (3x3) such that epipoles e and e' are mapped to the infinite point [1,0,0]^T\n",
    "\n",
    "rectRotLeft, rectRotRight, rectProjLeft, rectProjRight, Q, roi1, roi2 = cv.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], rotMatrix, transMatrix)\n",
    "\n",
    "mapLeft1, mapLeft2 = cv.initUndistortRectifyMap(newCameraMatrixL, distL, rectRotLeft, rectProjLeft, grayL.shape[::-1], cv.CV_32FC1)\n",
    "mapRight1, mapRight2 = cv.initUndistortRectifyMap(newCameraMatrixR, distR, rectRotRight, rectProjRight, grayR.shape[::-1], cv.CV_32FC1)\n",
    "\n",
    "#Load images\n",
    "imagesLeft = glob.glob('scanLeft/*.png')\n",
    "imagesRight = glob.glob('scanRight/*.png')\n",
    "\n",
    "#remap images\n",
    "def remap(imagesLeft, mapLeft1, mapLeft2, imagesRight, mapRight1, mapRight2):\n",
    "    remapLeft = []\n",
    "    remapRight = []\n",
    "    for i in range(len(imagesLeft)):\n",
    "        imgL = cv.imread(imagesLeft[i])\n",
    "        imgR = cv.imread(imagesRight[i])\n",
    "        remapLeft.append(cv.remap(imgL, mapLeft1, mapLeft2, cv.INTER_LINEAR))\n",
    "        remapRight.append(cv.remap(imgR, mapRight1, mapRight2, cv.INTER_LINEAR))\n",
    "        \n",
    "    return remapLeft, remapRight\n",
    "\n",
    "remapLeft, remapRight = remap(imagesLeft, mapLeft1, mapLeft2, imagesRight, mapRight1, mapRight2)\n",
    "\n",
    "def displayImagesRectified(remapLeft, remapRight):\n",
    "    for i in range(len(remapLeft)):\n",
    "        cv.resize(remapLeft[i], Size(), fx=0.5, fy=0.5)\n",
    "        cv.resize(remapRight[i], (0,0), fx=0.5, fy=0.5)\n",
    "        cv.imshow('rectifiedLeft', remapLeft[i])\n",
    "        cv.imshow('rectifiedRight', remapRight[i])\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd7334f14ef0712893308e64642052f720f5ca5fcf97acd16ddd48e16c040b4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
