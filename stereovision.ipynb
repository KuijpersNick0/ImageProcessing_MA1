{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stereovision\n",
    "\n",
    "![Suzanne](main.png)\n",
    "\n",
    "Stereovision is a discipline that deals with the reconstruction of 3D information from images. For the reconstruction of a point, several images of this point are needed. These images must be taken from different points of view. The key step of the reconstruction, which is often problematic, is to identify the images of the point to be reconstructed in each view.\n",
    "\n",
    "## Epipolar Geometry\n",
    "\n",
    "Epipolar geometry involves two cameras. The epipolar geometry describes the geometric properties between two views of the same scene and depends only on the intrinsic parameters of the cameras and their relative positions. It provides, in particular, the epipolar constraint, which will be very useful to produce the matches between views.\n",
    "\n",
    "## The Fondamental Matrix\n",
    "\n",
    "![Epipolar Geometry - Sanyam Kapoor](epipolar.png)\n",
    "\n",
    "Let us imagine that we have two images, right and left, of the world space. Let's take a point $\\vec{x}$ in the right image space. The point $\\vec{X}$ of the world space, of which $\\vec{x}$ is the image, can be anywhere on the line passing through $\\vec{x}$ and the optical center of the right camera. We will call this line the back-projected ray of $\\vec{x}$. Let us note $\\vec{x}'$ the image of $\\vec{X}$ in the left image space. The locus of $\\vec{x}'$ is therefore the image line of the back-projected ray of $\\vec{x}$. This line is called the epipolar line and is denoted $\\vec{l}'$. The epipolar line passes through the epipole $\\vec{e}'$, image of the optical center of the right camera.\n",
    "\n",
    "In 2D projective geometry, a line with equation $ax+by+c = 0$ is represented by a vector with three components $(a, b, c)^T$ defined to within one factor. Thus, we have the following relationship:\n",
    "\n",
    ">The point $\\vec{x}$ belongs to the line $\\vec{l}$ if and only if $x^T\\vec{l} = 0$.\n",
    "\n",
    "Moreover, in 2D projective geometry, the following remarkable relations are valid:\n",
    "\n",
    "- The intersection of two lines $l$ and $l'$ is given by $x = l \\times l'$,\n",
    "- The line passing through two points $x$ and $x'$ is given by $l = x \\times x'$.\n",
    "\n",
    "Note that the vector product can be written as a product of matrix $x \\times y = [x]_\\times y$ where\n",
    "\n",
    "$$[x]_\\times = \\begin{pmatrix} 0 & −x3 & x2 \\\\ x3 & 0 & −x1 \\\\ −x2 & x1 & 0 \\end{pmatrix}$$\n",
    "\n",
    "To find the equation of the epipolar line in the left image space, we just need to find the coordinates of two points of this line. The first is the image $P'\\vec{C}$ of the optical center $\\vec{C}$ of the right camera where $P'$ is the projection matrix of the left camera. The second is $P'P^{+}\\vec{x}$ where $P^{+}$ is the pseudo inverse of the projection matrix $P$ of the right camera. The epipolar line thus has the equation $l' = [P'\\vec{C}]_\\times{}P'P^{+}\\vec{x} = F\\vec{x}$ with $F = [P'\\vec{C}]_\\times{}P'P^{+}$. $F$ is called fundamental matrix.\n",
    "\n",
    "Since the epipolar line $\\vec{l}' = F\\vec{x}$ is the locus of $\\vec{x}'$, $\\vec{x}'$ therefore belongs to $\\vec{l}'$ which leads to the epipolar constraint :\n",
    "\n",
    ">**The fundamental matrix is such that for any pair of points corresponding $\\vec{x} \\leftrightarrow \\vec{x}'$ in the two images, we have $\\vec{x}'^{T}F\\vec{x} = 0$.**\n",
    "\n",
    "## Computation of the fundamental matrix\n",
    "\n",
    "The fundamental matrix $F$ has seven degrees of freedom. It has nine components but these are defined to within one scale factor, which removes one degree of freedom. Moreover, the matrix $F$ is a singular matrix ($det(F) = 0$) which gives us seven degrees of freedom. So we need at least seven correspondences to compute $F$. The equation $x'^{T}_iFx_i = 0$ and the seven correspondences allow us to write a system of equations of the form $Af = 0$, where $f$ is the vector which contains the components of the matrix $F$. Let us assume that $A$ is a 7×9 matrix of rank 7. The general solution of $Af = 0$ can be written $\\alpha f_1 + (1-\\alpha) f_2$ where $f_1$ and $f_2$ are two particular independent solutions of $Af = 0$. We then use the singularity constraint $det(\\alpha F_1 + (1 - \\alpha)F_2) = 0$ to determine $\\alpha$. Since the singularity constraint gives rise to a third degree equation, we may have one or three solutions for $F$.\n",
    "\n",
    "## OpenCV\n",
    "\n",
    "In practice you will use the OpenCV library. In python, you have access to its functions through the `cv2` module.\n",
    "\n",
    "You can find help with the calibration and reconstruction functions on the site https://docs.opencv.org/4.0.0/d9/d0c/group__calib3d.html\n",
    "\n",
    "## Goal\n",
    "\n",
    "In the zip of the statement you will find two sequences of images taken by two cameras during the scanning of an object by a laser plane.\n",
    "\n",
    "![Laser](scanRight/scan0010.png)\n",
    "\n",
    "You will also find shots of a checkerboard in different positions that will help you calibrate your cameras.\n",
    "\n",
    "![Damier](chessboards/c2Right.png)\n",
    "\n",
    "The goal is to reconstruct the scanned object in 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Etape 1 \n",
    "#Recuper les données de nos deux caméras\n",
    "\n",
    "#Prepa\n",
    "objp = np.zeros((7*7,3), np.float32) # tableau rempli de (0,0,0) * le nombre d'intersection\n",
    "objp[:,:2] = np.mgrid[0:7,0:7].T.reshape(-1,2) # Crée toutes les coord des intersections du damier (numéroter en fonction colonne et rangée)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane. (pixels)\n",
    "\n",
    "def getCam(images):\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    # CRIT_EPS : type criteria, 30 : nb max d'iteration, 0.001 : la précision\n",
    "\n",
    "\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #en gris\n",
    "\n",
    "        # F° qui trouve les coins\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (7,7), None) # Corners = pixels des intersections des carrés blancs et noirs de l'image \n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria) # augmente la precision\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            # img = cv2.drawChessboardCorners(img, (7,7), corners2, ret)\n",
    "            # cv2.imshow('img',img)\n",
    "            # cv2.waitKey(1000)\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, criteria)\n",
    "    # RMS error, matrice intrinseque de la camera, Distortion, vecteur rotation, vecteur translation\n",
    "    return ret, mtx, dist, rvecs, tvecs, corners2\n",
    "\n",
    "#Load images\n",
    "images = glob.glob('chessboards/c4*.png')\n",
    "\n",
    "#Appel F°\n",
    "ret, mtx, dist, rvecs, tvecs, corners = getCam(images)\n",
    " \n",
    "\n",
    "#matrice rotation, on utilise Rodrigues pour obtenir la matrice de rotation (3x3) à partir du vecteur de rotation (3x1)\n",
    "rmatRight = cv2.Rodrigues(rvecs[0])[0]\n",
    "rmatLeft = cv2.Rodrigues(rvecs[1])[0]\n",
    " \n",
    " \n",
    "#matrice translation -> On colle le vecteur translation a la matrice  de rotation, elle passe de 3x3 a une 3x4 (LxC)\n",
    "rotMatRight = np.concatenate((rmatRight,tvecs[0]), axis=1)\n",
    "rotMatLeft = np.concatenate((rmatLeft,tvecs[1]), axis=1)\n",
    "\n",
    " \n",
    "#matrice camera (cf Cours 1) -> MatriceIntrinsèque . MatriceRota (3x4 )\n",
    "camLeft = mtx @ rotMatLeft\n",
    "camRight = mtx @ rotMatRight\n",
    "\n",
    "#matrice intrinsèque \n",
    "KLeft = camLeft[:, :3] @ np.linalg.inv(rmatLeft)\n",
    "KRight = camRight[:, :3] @ np.linalg.inv(rmatRight)\n",
    "\n",
    "# Normalize intrinsic matrix K ====> Change rien ?\n",
    "KLeft = KLeft / KLeft[2, 2]\n",
    "KRight = KRight / KRight[2, 2]\n",
    "\n",
    "# matrice centre de projection -> (4x1 homogene) coordonnées de la camera\n",
    "posCamWorldCenterLeft = np.linalg.inv(np.concatenate((rotMatLeft,[[0,0,0,1]]), axis=0)) @ np.transpose([[0,0,0,1]])\n",
    "posCamWorldCenterRight = np.linalg.inv(np.concatenate((rotMatRight,[[0,0,0,1]]), axis=0)) @ np.transpose([[0,0,0,1]])\n",
    "\n",
    "\n",
    "def crossMat(v):\n",
    "    # Soit                          V = [[xxx][yyyy][zzzz]]\n",
    "    v = v[:,0]    # qui donne donc  V = [xxx yyyy zzzz]               \n",
    "            # Et on  retourne   ([[0000  -zzzz    yyyy]\n",
    "            #                   [zzzz   0000   -xxxx]\n",
    "            #                   [-yyyy  xxxx    0000]])\n",
    "\n",
    "    return np.array([[0,-v[2],v[1]] , [v[2],0,-v[0]] , [-v[1],v[0],0]])\n",
    "\n",
    "\n",
    "def matFondamental(camLeft,centerRight,camRight):\n",
    "    # pseudo inverse de la matrice camRight, qu'on multiplie par camLeft (= MatriceIntrinsèque @ MatriceRota)\n",
    "    # qu'on multiplie ensuite par (camLeft @centerRight) qui représente ...\n",
    "    # Et on fait finalement le cross product (produit vectoriel) de la matrice colonne resultat\n",
    "    return np.array(crossMat(camLeft @ centerRight) @ camLeft @ np.linalg.pinv(camRight))\n",
    "\n",
    "def matEssentiel(F, K1, K2):\n",
    "    # E = K2^T * F * K1\n",
    "    E = K2.T @ F @ K1\n",
    "    # Normalize \n",
    "    E = E / np.linalg.norm(E)\n",
    "    return E\n",
    "\n",
    "Fondamental = matFondamental(camLeft,posCamWorldCenterRight,camRight)\n",
    "Essential = matEssentiel(Fondamental, KLeft, KRight)\n",
    "\n",
    "#print(Fondamental)\n",
    "#print(np.linalg.matrix_rank(Fondamental))\n",
    "#print(Essential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.42146707e-02  2.13881367e-01  8.38852043e-03  1.00000000e+00\n",
      "   1.00000000e+00  1.00000000e+00]\n",
      " [ 3.48622151e-03  5.40045872e-02 -9.98529146e-01 -5.13797982e-20\n",
      "  -6.04440308e-20 -1.06046087e-17]\n",
      " [ 6.46749350e-02  9.73109047e-01  5.35646020e-02 -5.13797982e-20\n",
      "  -6.04440308e-20 -1.06046087e-17]]\n",
      "[[ 0.01421467  0.21388137  0.00838852]\n",
      " [ 0.00348622  0.05400459 -0.99852915]\n",
      " [ 0.06467493  0.97310905  0.0535646 ]]\n",
      "[[ 8.15988828e-19  2.14491883e-01 -3.30079004e-03]\n",
      " [-2.14491883e-01 -1.94573466e-18 -9.76720194e-01]\n",
      " [ 3.30079004e-03  9.76720194e-01  2.29849170e-19]]\n"
     ]
    }
   ],
   "source": [
    "#Etape 2\n",
    "\n",
    "# 1. For each pixel in first image find corresponding epipolar line in second images\n",
    "# 2. Examine all corresponding pixels on epipolar line and pick best match\n",
    "# 3. Triangulate matches to get depth information\n",
    "\n",
    "#Stereo rectification : on met les deux caméra à même \"hauteur\" => leur epilines vont coincider == scanlines\n",
    "#Step 1 : Find projective transformation HLeft and HRight (3x3) such that epipoles e and e' are mapped to the infinite point [1,0,0]^T\n",
    "\n",
    "def normalizedEpipole(F):\n",
    "    # Calculate left and right epipoles\n",
    "    eLeft = np.cross(F[:, 0], F[:, 1])\n",
    "    eRight = np.cross(F[:, 1], F[:, 0])\n",
    "    \n",
    "    # Normalize epipoles\n",
    "    eLeft = eLeft / np.linalg.norm(eLeft)\n",
    "    eRight = eRight / np.linalg.norm(eRight) \n",
    "    return eLeft, eRight\n",
    "\n",
    "eLeft, eRight = normalizedEpipole(Fondamental)\n",
    "# print(e_left)\n",
    "# print(e_right)\n",
    "\n",
    "def projectiveTransformationH(e, R):\n",
    "    # transformation projective H qui fait correspondre l'épipole normalisé e à [1,0,0]^T \n",
    "    # (un point consideré comme un point infini) avec l'utilisation de la matrice de rotation\n",
    "    #UTILISE DEF CROSS-MAT\n",
    "    RPrime = R @ np.array([[0, -e[2], e[1]], [e[2], 0, -e[0]], [-e[1], e[0], 0]])\n",
    "    \n",
    "    # Calculate translation vector t\n",
    "    t = np.array([[1], [0], [0]]) - RPrime @ e\n",
    "    \n",
    "    # Calculate projective transformation matrix H\n",
    "    H = np.hstack((RPrime, t))\n",
    "    \n",
    "    print(H)\n",
    "    #JAI PAS DU 3x3 car je pense camLeft pas centré ??\n",
    "    H = H[:, :3].reshape((3,3))\n",
    "\n",
    "    return H\n",
    "\n",
    "eLeftVect = np.array(eLeft)\n",
    "eLeftVect = eLeftVect.transpose()\n",
    "# print(eLeft)\n",
    "# print(eLeftVect)\n",
    "HLeft = projectiveTransformationH(eLeftVect, rmatLeft)\n",
    "# print(HLeft)\n",
    "\n",
    "def projectiveTransformationHR(H, R):\n",
    "    HRight = H @ R\n",
    "    return HRight\n",
    "\n",
    "HRight = projectiveTransformationHR(HLeft, rmatLeft.T)\n",
    "# print(HRight)\n",
    "\n",
    "\n",
    "def applyHToLeftRightImage():\n",
    "    return\n",
    "\n",
    "#Etape 3 \n",
    "#Correspondance search\n",
    "def correspondanceSearch():\n",
    "    #4techniques differentes\n",
    "    return\n",
    "\n",
    "#Etape 4 \n",
    "#Depth from disparity\n",
    "def depth():\n",
    "\n",
    "    # depth = z = (DistanceBaseline*f)/(x-x')\n",
    "    # Avec f = distance camera centre avec plan image\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd7334f14ef0712893308e64642052f720f5ca5fcf97acd16ddd48e16c040b4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
